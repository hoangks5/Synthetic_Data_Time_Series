{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "from statsmodels.tsa.statespace import sarimax\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from typing import List, Dict\n",
    "from gretel_client import configure_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching Gretel config to disk.\n",
      "Using endpoint https://api.gretel.cloud\n",
      "Logged in as hoang.nd@orai.io ✅\n"
     ]
    }
   ],
   "source": [
    "# Specify your Gretel API key\n",
    "\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "\n",
    "configure_session(api_key=\"prompt\", cache=\"yes\", validate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_amt</th>\n",
       "      <th>date</th>\n",
       "      <th>account_balance</th>\n",
       "      <th>credit_amt</th>\n",
       "      <th>district_id</th>\n",
       "      <th>debit_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50425.0</td>\n",
       "      <td>1995-04-30</td>\n",
       "      <td>485849.7</td>\n",
       "      <td>232833.8</td>\n",
       "      <td>77</td>\n",
       "      <td>182408.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22260.4</td>\n",
       "      <td>1995-03-31</td>\n",
       "      <td>435424.7</td>\n",
       "      <td>269788.6</td>\n",
       "      <td>77</td>\n",
       "      <td>247528.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94953.0</td>\n",
       "      <td>1995-02-28</td>\n",
       "      <td>413164.3</td>\n",
       "      <td>272404.2</td>\n",
       "      <td>77</td>\n",
       "      <td>177451.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13419.3</td>\n",
       "      <td>1994-11-30</td>\n",
       "      <td>476239.2</td>\n",
       "      <td>209552.5</td>\n",
       "      <td>77</td>\n",
       "      <td>196133.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-109497.2</td>\n",
       "      <td>1995-01-31</td>\n",
       "      <td>318211.3</td>\n",
       "      <td>209838.0</td>\n",
       "      <td>77</td>\n",
       "      <td>319335.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>320044.0</td>\n",
       "      <td>1996-02-29</td>\n",
       "      <td>997363.3</td>\n",
       "      <td>659139.6</td>\n",
       "      <td>4</td>\n",
       "      <td>339095.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>80647.8</td>\n",
       "      <td>1995-12-31</td>\n",
       "      <td>836115.8</td>\n",
       "      <td>434639.6</td>\n",
       "      <td>4</td>\n",
       "      <td>353991.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>-158796.5</td>\n",
       "      <td>1996-01-31</td>\n",
       "      <td>677319.3</td>\n",
       "      <td>408007.3</td>\n",
       "      <td>4</td>\n",
       "      <td>566803.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>44954.8</td>\n",
       "      <td>1996-03-31</td>\n",
       "      <td>1042318.1</td>\n",
       "      <td>453294.0</td>\n",
       "      <td>4</td>\n",
       "      <td>408339.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>28036.5</td>\n",
       "      <td>1995-11-30</td>\n",
       "      <td>755468.0</td>\n",
       "      <td>323189.3</td>\n",
       "      <td>4</td>\n",
       "      <td>295152.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5544 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       net_amt        date  account_balance  credit_amt  district_id  \\\n",
       "0      50425.0  1995-04-30         485849.7    232833.8           77   \n",
       "1      22260.4  1995-03-31         435424.7    269788.6           77   \n",
       "2      94953.0  1995-02-28         413164.3    272404.2           77   \n",
       "3      13419.3  1994-11-30         476239.2    209552.5           77   \n",
       "4    -109497.2  1995-01-31         318211.3    209838.0           77   \n",
       "...        ...         ...              ...         ...          ...   \n",
       "5539  320044.0  1996-02-29         997363.3    659139.6            4   \n",
       "5540   80647.8  1995-12-31         836115.8    434639.6            4   \n",
       "5541 -158796.5  1996-01-31         677319.3    408007.3            4   \n",
       "5542   44954.8  1996-03-31        1042318.1    453294.0            4   \n",
       "5543   28036.5  1995-11-30         755468.0    323189.3            4   \n",
       "\n",
       "      debit_amt  \n",
       "0      182408.8  \n",
       "1      247528.2  \n",
       "2      177451.2  \n",
       "3      196133.2  \n",
       "4      319335.2  \n",
       "...         ...  \n",
       "5539   339095.6  \n",
       "5540   353991.8  \n",
       "5541   566803.8  \n",
       "5542   408339.2  \n",
       "5543   295152.8  \n",
       "\n",
       "[5544 rows x 6 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load timeseries example to a dataframe\n",
    "\n",
    "data_source = \"https://gretel-public-website.s3.amazonaws.com/datasets/credit-timeseries-dataset.csv\"\n",
    "original_df = pd.read_csv(data_source)\n",
    "original_df.to_csv(\"original.csv\", index=False)\n",
    "original_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gretel Transforms Configuration\n",
    "config = \"\"\"\n",
    "schema_version: \"1.0\"\n",
    "models:\n",
    "    - transforms:\n",
    "        data_source: \"__tmp__\"\n",
    "        policies:\n",
    "            - name: shiftnumbers\n",
    "              rules:\n",
    "                - name: shiftnumbers\n",
    "                  conditions:\n",
    "                    field_name:\n",
    "                        - account_balance\n",
    "                        - credit_amt\n",
    "                        - debit_amt\n",
    "                        - net_amt\n",
    "                  transforms:\n",
    "                    - type: numbershift\n",
    "                      attrs:\n",
    "                        min: 1\n",
    "                        max: 100\n",
    "                        field_name:\n",
    "                            - date\n",
    "                            - district_id\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting poller\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"uid\": \"633ff763ec698b6d8072488e\",\n",
      "    \"guid\": \"model_2FnmzQ3kLaoLR3ModxbX6lDM7ug\",\n",
      "    \"model_name\": \"enthusiastic-grandiose-wolf\",\n",
      "    \"runner_mode\": \"cloud\",\n",
      "    \"user_id\": \"633ff67bbff621779f449273\",\n",
      "    \"user_guid\": \"user_2FnmWFhqEDJhOMwCmsPcFDdNX3q\",\n",
      "    \"billing_domain\": null,\n",
      "    \"billing_domain_guid\": null,\n",
      "    \"project_id\": \"633ff74d44a4f15b630a351f\",\n",
      "    \"project_guid\": \"proj_2FnmwfIx7oX7yUa3DKpWSaktQyH\",\n",
      "    \"status_history\": {\n",
      "        \"created\": \"2022-10-07T09:54:43.083103Z\"\n",
      "    },\n",
      "    \"last_modified\": \"2022-10-07T09:54:43.190509Z\",\n",
      "    \"status\": \"created\",\n",
      "    \"last_active_hb\": null,\n",
      "    \"duration_minutes\": null,\n",
      "    \"error_msg\": null,\n",
      "    \"error_id\": null,\n",
      "    \"traceback\": null,\n",
      "    \"annotations\": null,\n",
      "    \"container_image\": \"074762682575.dkr.ecr.us-west-2.amazonaws.com/gretelai/transforms@sha256:c9b59a72bc0f0d73111d7bc7e52a9c5b8cb6eb44734caa23dc02b1672fa7fc51\",\n",
      "    \"container_image_version\": \"2.10.0\",\n",
      "    \"model_type\": \"transform\",\n",
      "    \"config\": {\n",
      "        \"schema_version\": \"1.0\",\n",
      "        \"name\": null,\n",
      "        \"models\": [\n",
      "            {\n",
      "                \"transforms\": {\n",
      "                    \"data_source\": [\n",
      "                        \"gretel_512a77781d1245e289161ebc545aab79_credit-timeseries-dataset.csv\"\n",
      "                    ],\n",
      "                    \"ref_data\": {},\n",
      "                    \"policies\": [\n",
      "                        {\n",
      "                            \"name\": \"shiftnumbers\",\n",
      "                            \"rules\": [\n",
      "                                {\n",
      "                                    \"name\": \"shiftnumbers\",\n",
      "                                    \"conditions\": {\n",
      "                                        \"field_name\": [\n",
      "                                            \"account_balance\",\n",
      "                                            \"credit_amt\",\n",
      "                                            \"debit_amt\",\n",
      "                                            \"net_amt\"\n",
      "                                        ],\n",
      "                                        \"field_name_regex\": null,\n",
      "                                        \"field_name_similarity\": null,\n",
      "                                        \"field_label\": null,\n",
      "                                        \"field_attributes\": null,\n",
      "                                        \"value_label\": null\n",
      "                                    },\n",
      "                                    \"transforms\": [\n",
      "                                        {\n",
      "                                            \"type\": \"numbershift\",\n",
      "                                            \"attrs\": {\n",
      "                                                \"field_name\": null,\n",
      "                                                \"field_ref\": [\n",
      "                                                    \"date\",\n",
      "                                                    \"district_id\"\n",
      "                                                ],\n",
      "                                                \"min\": 1.0,\n",
      "                                                \"max\": 100.0,\n",
      "                                                \"precision\": 0\n",
      "                                            }\n",
      "                                        }\n",
      "                                    ]\n",
      "                                }\n",
      "                            ]\n",
      "                        }\n",
      "                    ],\n",
      "                    \"enable_classification_detail\": false,\n",
      "                    \"use_nlp\": false\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"notifications\": null,\n",
      "        \"label_predictors\": null\n",
      "    },\n",
      "    \"autouse_config\": null,\n",
      "    \"autouse_handler_id\": null\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Status is created. Model creation has been queued.\n",
      "INFO: Status is pending. A Gretel Cloud worker is being allocated to begin model creation.\n",
      "INFO: Status is active. A worker has started creating your model!\n",
      "2022-10-07T09:54:59.223625Z  Starting transforms model training\n",
      "2022-10-07T09:54:59.224349Z  Loading training data\n",
      "2022-10-07T09:54:59.455682Z  Using up to 10000 records for training\n",
      "2022-10-07T09:54:59.456110Z  Training data loaded\n",
      "2022-10-07T09:54:59.456607Z  Beginning transforms model training\n",
      "2022-10-07T09:55:23.642219Z  Saving model archive\n",
      "2022-10-07T09:55:23.644390Z  Saving training report\n",
      "2022-10-07T09:55:23.647861Z  Generating data preview with up to 100 records\n",
      "2022-10-07T09:55:23.719638Z  Done generating data preview\n",
      "2022-10-07T09:55:23.720824Z  Uploading artifacts to Gretel Cloud\n",
      "2022-10-07T09:55:24.465169Z  Model creation complete!\n",
      "INFO: Starting poller\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"uid\": \"633ff79fdae54ecd4ce57618\",\n",
      "    \"guid\": \"model_run_2Fnn6vKNXwnPKkYq4NXS3uJqy0k\",\n",
      "    \"model_name\": null,\n",
      "    \"runner_mode\": \"cloud\",\n",
      "    \"user_id\": \"633ff67bbff621779f449273\",\n",
      "    \"user_guid\": \"user_2FnmWFhqEDJhOMwCmsPcFDdNX3q\",\n",
      "    \"billing_domain\": null,\n",
      "    \"billing_domain_guid\": null,\n",
      "    \"project_id\": \"633ff74d44a4f15b630a351f\",\n",
      "    \"project_guid\": \"proj_2FnmwfIx7oX7yUa3DKpWSaktQyH\",\n",
      "    \"status_history\": {\n",
      "        \"created\": \"2022-10-07T09:55:43.516000Z\"\n",
      "    },\n",
      "    \"last_modified\": \"2022-10-07T09:55:43.648000Z\",\n",
      "    \"status\": \"created\",\n",
      "    \"last_active_hb\": null,\n",
      "    \"duration_minutes\": null,\n",
      "    \"error_msg\": null,\n",
      "    \"error_id\": null,\n",
      "    \"traceback\": null,\n",
      "    \"annotations\": null,\n",
      "    \"container_image\": \"074762682575.dkr.ecr.us-west-2.amazonaws.com/gretelai/transforms@sha256:c9b59a72bc0f0d73111d7bc7e52a9c5b8cb6eb44734caa23dc02b1672fa7fc51\",\n",
      "    \"container_image_version\": \"2.10.0\",\n",
      "    \"model_id\": \"633ff763ec698b6d8072488e\",\n",
      "    \"model_guid\": \"model_2FnmzQ3kLaoLR3ModxbX6lDM7ug\",\n",
      "    \"model_type\": \"transform\",\n",
      "    \"action\": \"transform\",\n",
      "    \"config\": {\n",
      "        \"data_source\": \"gretel_6e242dad8ae54826a34fb93ca400d7f4_credit-timeseries-dataset.csv\",\n",
      "        \"ref_data\": {},\n",
      "        \"params\": null\n",
      "    },\n",
      "    \"is_autouse\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Status is pending. A Gretel Cloud worker is being allocated to begin transforming records.\n"
     ]
    }
   ],
   "source": [
    "# De-identify the original dataset using the policy above\n",
    "import yaml\n",
    "\n",
    "from gretel_client.projects import create_or_get_unique_project\n",
    "from gretel_client.helpers import poll\n",
    "\n",
    "# Create a project and model configuration.\n",
    "project = create_or_get_unique_project(name=\"numbershift-transform\")\n",
    "\n",
    "model = project.create_model_obj(\n",
    "    model_config=yaml.safe_load(config), data_source=data_source\n",
    ")\n",
    "\n",
    "# Upload the training data.  Train the model.\n",
    "model.submit_cloud()\n",
    "poll(model)\n",
    "\n",
    "record_handler = model.create_record_handler_obj(data_source=data_source)\n",
    "record_handler.submit_cloud()\n",
    "poll(record_handler)\n",
    "\n",
    "deid_df = pd.read_csv(record_handler.get_artifact_link(\"data\"), compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the transformation report\n",
    "\n",
    "import json\n",
    "from smart_open import open\n",
    "\n",
    "report = json.loads(open(model.get_artifact_link(\"report_json\")).read())\n",
    "pd.DataFrame(report[\"metadata\"][\"fields\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we sort and remove \"net_amt\" as it's a derived column,\n",
    "# We will add back in after the data is synthesized\n",
    "train_df = deid_df.copy()\n",
    "\n",
    "train_df.sort_values(\"date\", inplace=True)\n",
    "train_cols = list(train_df.columns)\n",
    "train_cols.remove(\"net_amt\")\n",
    "train_df = train_df.filter(train_cols)\n",
    "\n",
    "# Here we noticed that some number have extremely long precision,\n",
    "# so we round the data\n",
    "train_df = train_df.round(1)\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_client.projects.models import read_model_config\n",
    "\n",
    "# Create a project and model configuration.\n",
    "project = create_or_get_unique_project(name=\"ts-5544-regular-seed\")\n",
    "\n",
    "# Pull down the default synthetic config.  We will modify it slightly.\n",
    "config = read_model_config(\"synthetics/default\")\n",
    "\n",
    "# Set up the seed fields\n",
    "seed_fields = [\"date\", \"district_id\"]\n",
    "\n",
    "task = {\n",
    "    \"type\": \"seed\",\n",
    "    \"attrs\": {\n",
    "        \"fields\": seed_fields,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Fine tune model parameters. These are the parameters we found to work best.  This is \"Run 20\" in the document\n",
    "config[\"models\"][0][\"synthetics\"][\"task\"] = task\n",
    "\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"vocab_size\"] = 20\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"learning_rate\"] = 0.005\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"epochs\"] = 100\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"gen_temp\"] = 0.8\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"reset_states\"] = True\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"dropout_rate\"] = 0.5\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"gen_temp\"] = 0.8\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"early_stopping\"] = True\n",
    "config[\"models\"][0][\"synthetics\"][\"privacy_filters\"][\"similarity\"] = None\n",
    "config[\"models\"][0][\"synthetics\"][\"privacy_filters\"][\"outliers\"] = None\n",
    "config[\"models\"][0][\"synthetics\"][\"generate\"][\"num_records\"] = train_df.shape[0]\n",
    "\n",
    "# Get a csv to work with, just dump out the train_df.\n",
    "deid_df.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "# Initiate a new model with the chosen config\n",
    "model = project.create_model_obj(model_config=config, data_source=\"train.csv\")\n",
    "\n",
    "# Upload the training data.  Train the model.\n",
    "model.submit_cloud()\n",
    "poll(model)\n",
    "\n",
    "synthetic = pd.read_csv(model.get_artifact_link(\"data_preview\"), compression=\"gzip\")\n",
    "synthetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add back in the derived column \"net_amt\"\n",
    "net_amt = synthetic[\"credit_amt\"] - synthetic[\"debit_amt\"]\n",
    "synthetic[\"net_amt\"] = net_amt\n",
    "\n",
    "# Save off the new synthetic data\n",
    "synthetic.to_csv(\"synthetic.csv\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the Synthetic Performance Report\n",
    "import IPython\n",
    "from smart_open import open\n",
    "\n",
    "IPython.display.HTML(data=open(model.get_artifact_link(\"report\")).read(), metadata=dict(isolated=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_district_averages(\n",
    "    synthetic: pd.DataFrame, training: pd.DataFrame, district_id: int\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    synthetic_data = synthetic.loc[synthetic[\"district_id\"] == district_id]\n",
    "    synthetic_data = synthetic_data.set_index(\"date\")\n",
    "\n",
    "    training_data = training.loc[training[\"district_id\"] == district_id]\n",
    "    training_data = training_data.set_index(\"date\")\n",
    "\n",
    "    combined = synthetic_data.join(\n",
    "        training_data, lsuffix=\"_synthetic\", rsuffix=\"_original\"\n",
    "    )\n",
    "    plt.suptitle(\"District #\" + str(district_id))\n",
    "\n",
    "    for col in [\"credit_amt\", \"debit_amt\", \"account_balance\"]:\n",
    "        fig = combined.plot(y=[f\"{col}_synthetic\", f\"{col}_original\"], figsize=(12, 8))\n",
    "        plt.title(\"Time Series for District #\" + str(district_id))\n",
    "\n",
    "    return combined\n",
    "\n",
    "\n",
    "combined = plot_district_averages(synthetic, train_df, 13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def ARIMA_run(\n",
    "    data_paths: List[str],\n",
    "    targets: List[str] = None,\n",
    "    entity_column: str = \"district_id\",\n",
    "    entities: List = None,\n",
    "    date_column: str = \"date\",\n",
    "    date_threshold: str = None,\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Purpose of this function is to automate the run and scoring of SARIMAX models, so we can benchmark results against various different synthetic data configurations.\n",
    "    The data paths from s3 are passed in, and then entire run, from loading in and sorting the data to creating a model and scoring it, is done via this function.\n",
    "    The outputs are the target scores for each variable on each dataset's model. This gets used to create bar charts of the RMSE.\n",
    "    With some fine tuning, this function can be made as a general purpose SARIMAX benchmark function for a variety of datasets.\n",
    "\n",
    "    Args:\n",
    "      data_paths: a list of paths to the data you want to create models and score with. These can be either local paths or ones from public buckets.\n",
    "      targets: Which columns in the data will be your target variables?\n",
    "      entity_column: This is purely used for datasets that have multiple time series data points from multiple places. Since this function was built with that in mind, it assumes that you will\n",
    "      give a column that denotes those different places/entities. If None is provided, no handler has been built yet that can handle that.\n",
    "      entities: This should be a list of the set of entities within the entity column.\n",
    "      date_column: This should be something we can use to sort the data, so that the time series is read appropriately.\n",
    "      date_threshold: This is to split the data into train and test. Whatever date you want to threshold by to make the train and test should be specified here.\n",
    "\n",
    "    Outputs:\n",
    "      target_scores: This will be a dictionary of RMSE scores for each target variable on each synthetic dataset.\n",
    "    \"\"\"\n",
    "    target_scores = {}\n",
    "    for target in targets:\n",
    "        target_scores[target] = []\n",
    "    for path in data_paths:\n",
    "        sorted_data = pd.read_csv(path)\n",
    "        sorted_data.sort_values(date_column, inplace=True)\n",
    "        sorted_data.drop_duplicates(subset=[date_column, entity_column], inplace=True)\n",
    "\n",
    "        print(\"Path: {}\".format(path))\n",
    "        for entity in entities:\n",
    "            print(\"Entity: {}\".format(entity))\n",
    "            for target in targets:\n",
    "                train_data = sorted_data[sorted_data[entity_column] == entity][\n",
    "                    sorted_data[date_column] < date_threshold\n",
    "                ]\n",
    "                test_data = sorted_data[sorted_data[entity_column] == entity][\n",
    "                    sorted_data[date_column] >= date_threshold\n",
    "                ]\n",
    "\n",
    "                model = sarimax.SARIMAX(\n",
    "                    train_data[target], order=(0, 1, 1), seasonal_order=(1, 1, 0, 12)\n",
    "                )\n",
    "                res = model.fit()\n",
    "\n",
    "                preds = res.forecast(len(test_data[target]))\n",
    "                rmse = mean_squared_error(test_data[target], preds, squared=False)\n",
    "                target_scores[target].append(rmse)\n",
    "                print(\"Target: {}\".format(target))\n",
    "                print(\"RMSE: {}\".format(rmse))\n",
    "\n",
    "    return target_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scores = ARIMA_run(\n",
    "    [\"synthetic.csv\", \"original.csv\"],\n",
    "    targets=[\"net_amt\", \"account_balance\", \"credit_amt\", \"debit_amt\"],\n",
    "    entities=[13],\n",
    "    date_threshold=\"1998-01-01\",\n",
    ")\n",
    "target_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "results = pd.DataFrame.from_dict(target_scores)\n",
    "results[\"method\"] = [\"synthetic\", \"real world\"]\n",
    "results.plot.bar(x=\"method\", title=\"RMSE per field and run in synthetic timeseries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
